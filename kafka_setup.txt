# ssh into box
ssh -i ~/.aws/HadoopCluster.pem ec2-user@<ec2-instance>


# Install Java 8
wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.rpm
sudo yum install -y jdk-8u141-linux-x64.rpm
java -version


# Install Kafka
1. wget http://mirrors.advancedhosters.com/apache/kafka/0.10.2.1/kafka_2.11-0.10.2.1.tgz
2. tar -xzf kafka_2.11-0.10.2.1.tgz
3. rm kafka_2.11-0.10.2.1.tgz

# Zookeeper Properties
1. sudo mkdir -p /var/zookeeper/data
2. sudo chown -R ec2-user /var/zookeeper
3. vi kafka_2.11-0.10.2.1/config/zookeeper.properties

dataDir=/var/zookeeper/data
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0

server.1=<ec2-instance-1>:2888:3888
server.2=<ec2-instance-2>:2888:3888
# Add more servers if you want to
initLimit=5
syncLimit=2

4. On <ec2-instance-1> run echo "1" > /var/zookeeper/data/myid
5. On <ec2-instance-2> run echo "2" > /var/zookeeper/data/myid
6. Run above respective echo "no" cmd on all ec2-instances


# Start Kafka Server
1. cd kafka_2.11-0.10.2.1/
2. sudo mkdir /var/kafka/data
3. sudo chown -R ec2-user /var/kafka
2. change following properties in config/server.properties:
        # Change broker id in multi node cluster
        broker.id={id}

        # Change Log Dir
        log.dirs=/var/kafka/data

        # Change zookeeper connect string
        zookeeper.connect=ec2-54-160-85-68.compute-1.amazonaws.com:2181,ec2-54-226-72-146.compute-1.amazonaws.com:2181

        # to enable communication change listeners to public dns name in each ec2 instance respectively
        listeners=PLAINTEXT://<ec2-instance-1>:9092

        # log retention hours to save disk space
        log.retention.hours=1

        # log retention check interval
        log.retention.check.interval.ms=300000

        # How much data you want to retain	
        log.retention.bytes=134217728

        # Each log segment size
	log.segment.bytes=134217728



# Start Zookeeper
nohup bin/zookeeper-server-start.sh config/zookeeper.properties > ~/zookeeper-logs 2>&1 &


# Start Kafka server
nohup bin/kafka-server-start.sh config/server.properties > ~/kafka-logs 2>&1 &


# Create Kafka Topic
bin/kafka-topics.sh --zookeeper <ec2-instance-1>:2181,<ec2-instance-2>:2181 --create --topic maxwell --partitions 100 --replication-factor 2


# To change retention for topic as well: 
bin/kafka-configs.sh --zookeeper localhost --alter --entity-type topics --entity-name maxwell --add-config retention.ms=1800000


# List Topics
bin/kafka-topics.sh --zookeeper <ec2-instance-1>:2181,<ec2-instance-2>:2181 --list


# Start CLI Producer
bin/kafka-console-producer.sh --broker-list <ec2-instance-1>:9092,<ec2-instance-2>:9092 --topic test


# Start CLI Consumer
bin/kafka-console-consumer.sh --bootstrap-server <ec2-instance-1>:9092,<ec2-instance-2>:9092 --topic test --from-beginning



Useful Resource: https://aws.amazon.com/blogs/big-data/real-time-stream-processing-using-apache-spark-streaming-and-apache-kafka-on-aws/